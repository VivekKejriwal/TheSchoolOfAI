{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "authorship_tag": "ABX9TyPRWaGTV93j/vzii5QRYRKS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VivekKejriwal/TheSchoolOfAI/blob/main/Assignment_3ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRhRsisQrMmi"
      },
      "source": [
        "#!pip install torch"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcdIOOmZracH"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n",
        "import torch.nn as nn\r\n",
        "import torch.utils\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torch.autograd\r\n",
        "import torch.optim as optim\r\n",
        "from torchsummary import summary"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUqXwPNtrq8m"
      },
      "source": [
        "class Network(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "    self.conv1= nn.Conv2d(in_channels=1  ,out_channels=10 ,kernel_size=3)         #28X28X1  >>26x26X10    #RF 3\r\n",
        "    self.conv2= nn.Conv2d(in_channels=10 ,out_channels=10 ,kernel_size=3)         #26X26X10 >>24X24X10    #RF 5 \r\n",
        "    self.conv3= nn.Conv2d(in_channels=10 ,out_channels=20 ,kernel_size=3)         #12X12X10 >>10X10X20    #RF 12\r\n",
        "    self.conv4= nn.Conv2d(in_channels=20 ,out_channels=20 ,kernel_size=3)         #10X10X20 >>8X8X20      #RF 14\r\n",
        "    self.conv5= nn.Conv2d(in_channels=20 ,out_channels=30 ,kernel_size=3)         #4X4X20   >>2X2X30      #RF 30\r\n",
        "    self.pool=  nn.AvgPool2d(2,2)                                                 #2X2X30   >>1X1X30      #RF 30\r\n",
        "    self.out  = nn.Linear(in_features= 1*1*30,out_features=1000)                  #1X1X30   >>1X1000\r\n",
        "\r\n",
        "  def forward(self,t):\r\n",
        "    #input layer\r\n",
        "    t=t\r\n",
        "    \r\n",
        "    #First hidden layer\r\n",
        "    t=F.relu(self.conv1(t))\r\n",
        "    t=F.relu(self.conv2(t))\r\n",
        "\r\n",
        "    #1st maxpool layer\r\n",
        "    t=F.max_pool2d(t, kernel_size=2, stride=2)\r\n",
        "\r\n",
        "    #2nd hidden layer\r\n",
        "    t=F.relu(self.conv3(t))\r\n",
        "    t=F.relu(self.conv4(t))\r\n",
        "\r\n",
        "    #2nd max-pool layer\r\n",
        "    t=F.max_pool2d(t,kernel_size=2,stride=2)\r\n",
        "\r\n",
        "    #3rd layer\r\n",
        "    t=F.relu(self.conv5(t))\r\n",
        "\r\n",
        "    #GAP layer\r\n",
        "    t=self.pool(t)\r\n",
        "\r\n",
        "    #Fully connected layer\r\n",
        "    t=t.reshape(-1,1*1*30)\r\n",
        "    t=self.out(t)\r\n",
        "\r\n",
        "    return F.softmax(t,dim=1)\r\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q8chRK9_X5I",
        "outputId": "87461495-3666-40f4-8cc4-dc2e6c82093a"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()   #USING GPU\r\n",
        "device = torch.device(\"cuda\" if use_cuda else 'cpu')\r\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\r\n",
        "network= Network().to(device)   #Transferring network to GPU\r\n",
        "\r\n",
        "for name,param in network.named_parameters():\r\n",
        "  print(name,'\\t\\t',param.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.weight \t\t torch.Size([10, 1, 3, 3])\n",
            "conv1.bias \t\t torch.Size([10])\n",
            "conv2.weight \t\t torch.Size([10, 10, 3, 3])\n",
            "conv2.bias \t\t torch.Size([10])\n",
            "conv3.weight \t\t torch.Size([20, 10, 3, 3])\n",
            "conv3.bias \t\t torch.Size([20])\n",
            "conv4.weight \t\t torch.Size([20, 20, 3, 3])\n",
            "conv4.bias \t\t torch.Size([20])\n",
            "conv5.weight \t\t torch.Size([30, 20, 3, 3])\n",
            "conv5.bias \t\t torch.Size([30])\n",
            "out.weight \t\t torch.Size([1000, 30])\n",
            "out.bias \t\t torch.Size([1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrywDniTaDiM"
      },
      "source": [
        "#Defining the training set for EMNIST data\r\n",
        "\r\n",
        "train_set = torchvision.datasets.EMNIST(\r\n",
        "    root = './data',\r\n",
        "    split = 'letters',\r\n",
        "    train = True ,\r\n",
        "    download = True,\r\n",
        "    transform = transforms.Compose([\r\n",
        "          transforms.ToTensor()\r\n",
        "        ])\r\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WjveFnjUJh6"
      },
      "source": [
        "#Function to calculate number of correct predicitons in images\r\n",
        "\r\n",
        "def get_num_correct(preds, labels):\r\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDzDViMcwSwb",
        "outputId": "3a5caa80-dd1b-4177-86ef-7de5715fc88f"
      },
      "source": [
        "#Defining the loader for training with batch size of 100\r\n",
        "\r\n",
        "train_loader= torch.utils.data.DataLoader(train_set,batch_size=100, shuffle=True, **kwargs)\r\n",
        "\r\n",
        "optimizer= optim.SGD(network.parameters(), lr=0.1, momentum=0.9) #Stochastic Gradient Descent \r\n",
        "\r\n",
        "for epoch in range(20):\r\n",
        "  total_loss=0\r\n",
        "  total_correct=0\r\n",
        "\r\n",
        "  for batch in train_loader:  #Get Batch\r\n",
        "    images, labels = batch\r\n",
        "    images, labels= images.to(device), labels.to(device)\r\n",
        "    preds= network(images) #Pass batch of images\r\n",
        "    \r\n",
        "    loss= F.cross_entropy(preds, labels) #Calculate Loss\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    loss.backward() #Calculate gradients\r\n",
        "    optimizer.step() #Update the weights\r\n",
        "\r\n",
        "    total_loss+= loss.item() #Add losses\r\n",
        "    total_correct+= get_num_correct(preds, labels) #Add total number of correct predicitons\r\n",
        "    \r\n",
        "  print(\"epoch\",epoch,\"total correct:\",total_correct,\"loss:\",total_loss)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 total correct: 2137 loss: 8620.82691001892\n",
            "epoch 1 total correct: 4760 loss: 8620.711944580078\n",
            "epoch 2 total correct: 4851 loss: 8585.183608531952\n",
            "epoch 3 total correct: 4800 loss: 8575.020342350006\n",
            "epoch 4 total correct: 4800 loss: 8575.020339012146\n",
            "epoch 5 total correct: 4800 loss: 8575.020339012146\n",
            "epoch 6 total correct: 4800 loss: 8575.020346164703\n",
            "epoch 7 total correct: 4800 loss: 8575.020344257355\n",
            "epoch 8 total correct: 4800 loss: 8575.02035522461\n",
            "epoch 9 total correct: 4800 loss: 8575.020342350006\n",
            "epoch 10 total correct: 4800 loss: 8575.020337104797\n",
            "epoch 11 total correct: 4800 loss: 8575.02035522461\n",
            "epoch 12 total correct: 4800 loss: 8575.02033996582\n",
            "epoch 13 total correct: 4800 loss: 8575.020347118378\n",
            "epoch 14 total correct: 4800 loss: 8575.020342350006\n",
            "epoch 15 total correct: 4800 loss: 8575.020347595215\n",
            "epoch 16 total correct: 4800 loss: 8575.020338058472\n",
            "epoch 17 total correct: 4800 loss: 8575.020342826843\n",
            "epoch 18 total correct: 4800 loss: 8575.020337104797\n",
            "epoch 19 total correct: 4800 loss: 8575.020339012146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g71TY29bE-Y"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}